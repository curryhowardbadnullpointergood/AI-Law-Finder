:
Empirical laws are mathematical generalisations found through observing the physical world. It has taken us
centuries of gathering data, keen research along with repeated experiments, and no doubt plenty of talented sci-
entists to discover these laws. Leading us to understand everything from the mysteries that govern the collision
of two objects to the shape of the path planets thread upon.
Recent advances in neural networks including increases in computational power permit us to train models, that
replicate, fasten and automate our discovery of empirical laws. This extends to even noisy chaotic systems such
as the double pendulum. Combined with white box models, symbolic regression and explanable A.I., we can
peer into the ”mind,” of how such models, process data and conclude their observations. Human congition is
inherently finite in its capacity for thought and observational ability, has been historically overcome through the
development of new tools such as the microscope. Similarly, congitive biases can be mitigated, by utillising
artificial intelligence, which is a rapidly emerging technology capable of expanding our perception and analysis.


I have read and understood the ECS Academic Integrity information and the University’s Academic Integrity
Guidance for Students.
- I am aware that failure to act in accordance with the Regulations Governing Academic Integrity may lead to
the imposition of penalties which, for the most serious cases, may include termination of programme.
- I consent to the University copying and distributing any or all of my work in any form and using third parties
(who may be based outside the EU/EEA) to verify whether my work contains plagiarised material, and for
quality assurance purposes.
You must change the statements in the boxes if you do not agree with them.
We expect you to acknowledge all sources of information (e.g. ideas, algorithms, data) using citations. You
must also put quotation marks around any sections of text that you have copied without paraphrasing. If any
figures or tables have been taken or modified from another source, you must explain this in the caption and cite
the original source.
I have acknowledged all sources, and identified any content taken from elsewhere.
If you have used any code (e.g. open-source code), reference designs, or similar resources that have been pro-
duced by anyone else, you must list them in the box below. In the report, you must explain what was used and
how it relates to the work you have done.
I have not used any resources produced by anyone else.
You can consult with module teaching staff/demonstrators, but you should not show anyone else your work
(this includes uploading your work to publicly-accessible repositories e.g. Github, unless expressly permitted
by the module leader), or help them to do theirs. For individual assignments, we expect you to work on your
own. For group assignments, we expect that you work only with your allocated group. You must get permission
in writing from the module teaching staff before you seek outside assistance, e.g. a proofreading service, and
declare it here.
I did all the work myself, or with my allocated group, and have not helped anyone else.
We expect that you have not fabricated, modified or distorted any data, evidence, references, experimental re-
sults, or other material used or presented in the report. You must clearly describe your experiments and how the
results were obtained, and include all data, source code and/or designs (either in the report, or submitted as a
separate file) so that your results could be reproduced.
The material in the report is genuine, and I have included all my data/code/designs.
We expect that you have not previously submitted any part of this work for another assessment. You must get
permission in writing from the module teaching staff before re-using any of your previously submitted work for
3this assessment.
I have not submitted any part of this work for another assessment.
If your work involved research/studies (including surveys) on human participants, their cells or data, or on
animals, you must have been granted ethical approval before the work was carried out, and any experiments
must have followed these requirements. You must give details of this in the report, and list the ethical approval
reference number(s) in the box below.
My work did not involve human participants, their cells or data, or animals.
ECS Statement of Originality Template, updated August 2018, Alex Weddell aiofficer@ecs.soton.ac.uk

Prior to the commencement of this project, a risk assessment was conducted to anticipate potential challenges
and plan mitigation strategies. This proactive approach aimed to ensure a smoother development process. Sev-
eral risks did materialize during the course of the work; however, thanks to the preparations made, they were
effectively managed and did not significantly hinder progress.
IssueImpactProbRisk
Unexpected delays and accidents337
Unable to generate enough
experimental data due to lack
of computational power.4114
Challenges learning the
pendulum laws and the derivation245
Interpretability Challenges3210
Symbolic Regression Failure349
Scope Creep2214
7.2
Mitigation
Include contingency plans and a 3 week
break between major stages of the project,
to allow for unexpected incidents.of the project,
to allow for unexpected incidents.
Explore alternate more efficient ways of
simulating data, consider using cloud
infrastructure or potentially the
Universities HPC facilities.
Seek other resources from the Physics Department
to learn the Physics required. Look up
explanations online to learn.
Challenges in interpreting how the model
works, can be mitigated through visualising
the data, plotting results and through
seeking ways to explain the model.
Research and select appropriate SR algorithms/libraries; Start with a simple
operator set; Test on synthetic data with known solutions.
Define clear project scope and deliverables at the start; Use a detailed
timeline with milestones; Regularly review progress against the plan.
Gantt Charts:
A Gantt chart along with a rough outline of the relevent dates for various submission was made towards the
beginning of this project, this also included contengency planning and short yet frequent breaks every couple
weeks. Furthermore also made a gantt chart to compare the actual timeline vs the prediction made.
41What actually ended up happnening:
7.3
Project Reflection:
In reflection, the symbolic regressor was successful and has demonstrated all of the goals initially outlined,
successfully deriving the expected formulas. However, one extension that was intended—deriving a chaotic
system like a double pendulum—proved to be extremely difficult and ultimately impossible with the current
architecture. Even after removing the dimensions from the data and eliminating constants, the sheer number
of variables involved in predicting angular momentum, along with the fact that it is a coupled system, made
the regressor’s design inadequate. Even when the dataset was split and the data fed in individually, the search
space remained large, and valid expressions only emerged at a recursive depth of 5. This depth led to a total
of 254,803,968 possible searches—an amount which, by calculation, would take longer than the age of the uni-
verse to solve using the current algorithm.
42Figure 9: (a) Static double pendulum
Figure 10: (b) Double pendulum path
Figure 11: Side-by-side visualisation of a double pendulum’s static setup and path.
Having never previously worked on a project of this academic scale, this was a novel experience. Every de-
cision and design choice had to be justified with prior research and academic references, making the process
significantly more demanding than expected. Justifying the architectural choices and constantly being under
pressure to produce valid expressions drove the development of the regressor in the most effective way possible.
A Golang version of the regressor was briefly explored but wisely abandoned due to time constraints, allowing
focus to return to writing the report. Some aspects of the project took far longer than anticipated, and attempts
to collaborate with authors of referenced papers were unsuccessful, as no responses were received.
An agile approach would not have worked well in this context. It proved more valuable to focus on the overall
design, plan for the long term, and rigorously test components throughout, rather than developing a half-baked
and ineffective core. This rationale guided the early stages, which involved careful library selection and thor-
ough research into various strategies before committing to a design. Each function was rigorously tested upon
writing to ensure speed, effectiveness, and correctness. Modules were developed in such a way that, when
combined, the main regressor worked with minimal or no significant bugs. Furthermore, planning contingency
time in the form of short but frequent breaks proved highly beneficial and was far more effective than reserving
all available time until the end.
While implementing, designing, testing, and writing the project and report was challenging, the process led to
the development of several key research skills—such as referencing properly, reading academic papers more
systematically, and learning that seemingly minor details can cause the longest delays. It became clear that it
is ambitious and often unwise to expect to achieve absolutely everything envisioned at the start of a project. It
is always better to err on the side of caution—promise little and overdeliver, rather than the opposite. Work-
ing at the intersection of machine learning and its applications in other domains such as biology and physics
has highlighted the immense potential of machine learning. It has shown how tools based on algorithms and
computation can solve problems that once required exceptional human insight—now solved by silicon and code.
438
Conclusion:
To summarise the goal of this project is to explore deriving physical laws through AI, and helping automate the
discovery of emphirical laws. Hopefully, this would help speed up the process of discovering new laws, in data,
as well as remove the inherent human bias towards creating expressions. A significant amount of attention was
placed on reimplementing the regressor from scratch in a more modern and maintainable language, in order to
make it easier for future improvements to be made. Also I’ve used the least amount of libriries possible (numpy
and sumpy), in order to build this, allowing it to be really easy to maintain the codebase. It has sucesfully
derived the resulted expected and has generated a series of complex expressions for describing data.
future works
genetic programming can help prune even more, and is seful for approximations, trainable meijer g functions ,
Crabbe et al. 2020), Alaa van der Schaar 2019 Genetic programming (GP) has traditionally been a core tech-
nique for symbolic regression [references...], although challenges related to scaling and overfitting have been
noted (see discussion in Abdellaoui Mehrkanoon, 2021, citing [24]), leading to the exploration of alternative
methods.
